# -*- coding: utf-8 -*-
"""Finding Similar Sentences.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mo598_RkTT_vAY2rmJYFg5tbS2yCfYSo
"""

import random
import time 
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sys
import operator

def fileRead(name):
    content=[]
    with open(name) as f:
      lines = f.readlines()
      for l in lines:
        content.append(l.strip('\n'))

    return content
# covert sentence to character based
def covertS(name):
    content = fileRead(name)
    covertSList = []
 #  print(content[0])     1st sentences
    for i in range(0,len(content)):
        sentence = content[i].replace(' ','')     # remove space ' '
        sentence = sentence.strip('.')            # remove '.'
        covertSList.append(sentence.lower())      # change lowercase
    return covertSList
# covert sentence to word based
def covertSWord(name):
    content = fileRead(name)
    covertSWordList = []
    for i in range(0,len(content)):
        sentence = content[i].strip('.')                # remove '.'
        covertSWordList.append(sentence.lower())      # change lowercase
    return covertSWordList

def twoGrams(content):
    twoGramsMap = {}
    count =0
    twoGramsNumList = []
    TemptyList=[]
    for before in range(0,len(content)):             # total sentences loop;  before: index of all sentences
      sentenceLen = len(content[before])
      for after in range(0,sentenceLen-1):           # one sentences loop;    after : index of one sentence
          twoChar = content[before][after:after+2]   # content[0][14:len(content[0])
#         print(twoChar)
          if twoChar not in twoGramsMap:
            count = count+1
            twoGramsMap[twoChar]= count
            TemptyList.append(twoGramsMap[twoChar]) 
          elif twoChar in twoGramsMap:  
            TemptyList.append(twoGramsMap[twoChar]) 
      twoGramsNumList.append(TemptyList) 
      TemptyList=[]

    print('The length of character based 2-grams : ',len(twoGramsMap))     
 #   print('twoGramsMap==>',twoGramsMap)
 #   print('twoGramsNumList==>',twoGramsNumList)
    return twoGramsNumList

def threeGrams(content):
    threeGramsMap = {}
    count =0
    threeGramsNumList = []
    TemptyList=[]
    for before in range(0,len(content)):             # total sentences loop;  before: index of all sentences
      sentenceLen = len(content[before])
      for after in range(0,sentenceLen-2):           # one sentences loop;    after : index of one sentence
          threeChar = content[before][after:after+3]   # content[0][14:len(content[0])
          if threeChar not in threeGramsMap:
            count = count+1
            threeGramsMap[threeChar]= count
            TemptyList.append(threeGramsMap[threeChar]) 
          elif threeChar in threeGramsMap:  
            TemptyList.append(threeGramsMap[threeChar]) 
      threeGramsNumList.append(TemptyList) 
      TemptyList=[]

    print('The length of character based 3-grams : ',len(threeGramsMap))   
 #   print('threeGramsMap==>',threeGramsMap)
 #   print('threeGramsNumList==>',threeGramsNumList)
    return threeGramsNumList

def wordtwoGrams(content):
    wordtwoGramsMap = {}
    count =0
    wordtwoGramsNumList = []
    TemptyList=[]    
    for before in range(0,len(content)):             # total sentences loop;  before: index of all sentences
      wordListLen= len(content[before].split())      # eg: len(['the', 'sun', 'was', 'shining'])= 4
      for after in range(0,wordListLen-1):
         a = content[before].split()[after]
         b = content[before].split()[after+1]
         twoWords = a+b
         if twoWords not in wordtwoGramsMap:
            count = count+1
            wordtwoGramsMap[twoWords]= count
            TemptyList.append(wordtwoGramsMap[twoWords]) 
         elif twoWords in wordtwoGramsMap:  
            TemptyList.append(wordtwoGramsMap[twoWords]) 
      wordtwoGramsNumList.append(TemptyList) 
      TemptyList=[]

    print('The length of word based 2-grams : ',len(wordtwoGramsMap)) 
 #   print('wordTwoGramsMap==>',wordtwoGramsMap)
 #   print('wordTwoGramsNumList==>',wordtwoGramsNumList)
    return wordtwoGramsNumList

def jaccar(Alist):
  jaccarValueMap = {}            # Key is line number, eg: 1,2 ==> line 1 compareTo line 2. Value(jaccarValue) = intersectioin/union
  for i in range(0,len(Alist)):  #len(Alist)
    for j in range(i+1,len(Alist)):
       inter =  set(Alist[i]).intersection(set(Alist[j]))   #intersectioin
       un= set(Alist[i]).union(set(Alist[j]))               #union
       jaccarValue = len(inter)/len(un)
       key = str(i+1)+','+ str(j+1)
       jaccarValueMap[key]= jaccarValue
    #   print('Sentence #',i+1,'compare to #',j+1, 'intersectioin/union = ',jaccarValue)  
  print('jaccarValueMap==>',jaccarValueMap)
  sortedDict = sorted(jaccarValueMap.items(), key=operator.itemgetter(1), reverse=True)
  print('sorted jaccarValueMap==>',sortedDict)
  for index in range(0,5):
     print(sortedDict[index])


if __name__ == '__main__':
    def test():
        contentVSS = covertS('Random very short sentences.txt')
        contentSS = covertS('Random short sentences.txt')
        contentLS = covertS('Random long sentences.txt')     
        contentSpanishS = covertS('Random spanish sentences.txt')
        print("------------------- Random very short sentences -------------------")
     #  print(contentVSS), char
        print("--------CHARACTER BASED 2-GRAMS---------")
        jaccar(twoGrams(contentVSS))
        print("--------CHARACTER BASED 3-GRAMS---------")
        jaccar(threeGrams(contentVSS))
        print("--------WORD BASED 2-GRAMS---------")
     #  print(contentVSSWord), word
        contentVSSWord = covertSWord('Random very short sentences.txt')  
        jaccar(wordtwoGrams(contentVSSWord))

        print("\n--------------------- Random short sentences ----------------------")
     #  print(contentSS), char
        print("--------CHARACTER BASED 2-GRAMS---------")
        jaccar(twoGrams(contentSS))
        print("--------CHARACTER BASED 3-GRAMS---------")
        jaccar(threeGrams(contentSS))
        print("--------WORD BASED 2-GRAMS---------")
     #  print(contentSSWord), word   
        contentSSWord = covertSWord('Random short sentences.txt')
        jaccar(wordtwoGrams(contentSSWord))

        print("\n--------------------- Random long sentences ----------------------")
     #  print(contentLS), char
        print("--------CHARACTER BASED 2-GRAMS---------")
        jaccar(twoGrams(contentLS))
        print("--------CHARACTER BASED 3-GRAMS---------")
        jaccar(threeGrams(contentLS))
        print("--------WORD BASED 2-GRAMS---------")
     #  print(contentLSWord), word   
        contentLSWord = covertSWord('Random long sentences.txt')
        jaccar(wordtwoGrams(contentLSWord))

        print("\n--------------------- Random spanish sentences ----------------------")
     #  print(contentSpanishS), char
        print("--------CHARACTER BASED 2-GRAMS---------")
        jaccar(twoGrams(contentSpanishS))
        print("--------CHARACTER BASED 3-GRAMS---------")
        jaccar(threeGrams(contentSpanishS))
        print("--------WORD BASED 2-GRAMS---------")
     #  print(contentSpanishSWord), word   
        contentSpanishSWord = covertSWord('Random spanish sentences.txt')
        jaccar(wordtwoGrams(contentSpanishSWord))

    test()